{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b784c8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from PySide6.QtWidgets import QWidget, QVBoxLayout, QLabel, QSlider, QPushButton, QComboBox, QStackedWidget, QDoubleSpinBox, QGridLayout\n",
    "from PySide6.QtCore import Qt, Signal\n",
    "import numpy as np\n",
    "import imageio # For general image loading (can use Pillow too)\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "from skimage.color import rgb2gray\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "from modules.i_image_module import IImageModule\n",
    "from image_data_store import ImageDataStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e17e6b",
   "metadata": {
    "title": "--- Parameter Widgets for Different Operations ---"
   },
   "outputs": [],
   "source": [
    "##\n",
    "class BaseParamsWidget(QWidget):\n",
    "    \"\"\"Base class for parameter widgets to ensure a consistent interface.\"\"\"\n",
    "    def get_params(self) -> dict:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class NoParamsWidget(BaseParamsWidget):\n",
    "    \"\"\"A placeholder widget for operations with no parameters.\"\"\"\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "        layout = QVBoxLayout(self)\n",
    "        label = QLabel(\"This operation has no parameters.\")\n",
    "        label.setStyleSheet(\"font-style: italic; color: gray;\")\n",
    "        layout.addWidget(label)\n",
    "        layout.addStretch()\n",
    "\n",
    "    def get_params(self) -> dict:\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c73707-0250-47c1-b78c-56d3ad14ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "class GaussianParamsWidget(BaseParamsWidget):\n",
    "    \"\"\"A widget for Gaussian blur parameters.\"\"\"\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "        layout = QVBoxLayout(self)\n",
    "        layout.setContentsMargins(0, 0, 0, 0)\n",
    "        layout.addWidget(QLabel(\"Sigma (Standard Deviation):\"))\n",
    "        self.sigma_spinbox = QDoubleSpinBox()\n",
    "        self.sigma_spinbox.setMinimum(0.1)\n",
    "        self.sigma_spinbox.setMaximum(25.0)\n",
    "        self.sigma_spinbox.setValue(1.0)\n",
    "        self.sigma_spinbox.setSingleStep(0.1)\n",
    "        layout.addWidget(self.sigma_spinbox)\n",
    "        layout.addStretch()\n",
    "\n",
    "    def get_params(self) -> dict:\n",
    "        return {'sigma': self.sigma_spinbox.value()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11567253-425d-46a5-b223-7b5708d67f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "class PowerLawParamsWidget(BaseParamsWidget):\n",
    "    \"\"\"A widget for Power Law (Gamma) Transformation.\"\"\"\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "        layout = QVBoxLayout(self)\n",
    "        layout.setContentsMargins(0, 0, 0, 0)\n",
    "        layout.addWidget(QLabel(\"Gamma:\"))\n",
    "        self.gamma_spinbox = QDoubleSpinBox()\n",
    "        self.gamma_spinbox.setMinimum(0.01)\n",
    "        self.gamma_spinbox.setMaximum(5.0)\n",
    "        self.gamma_spinbox.setValue(1.0)\n",
    "        self.gamma_spinbox.setSingleStep(0.1)\n",
    "        layout.addWidget(self.gamma_spinbox)\n",
    "        layout.addStretch()\n",
    "\n",
    "    def get_params(self) -> dict:\n",
    "        return {'gamma': self.gamma_spinbox.value()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce5f355-27ea-426e-b6da-395faa09c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "class ConvolutionParamsWidget(BaseParamsWidget):\n",
    "    \"\"\"A widget for defining a 3x3 convolution kernel.\"\"\"\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "        layout = QVBoxLayout(self)\n",
    "        layout.setContentsMargins(0, 0, 0, 0)\n",
    "        layout.addWidget(QLabel(\"3x3 Kernel:\"))\n",
    "        \n",
    "        grid_layout = QGridLayout()\n",
    "        self.kernel_inputs = []\n",
    "        for r in range(3):\n",
    "            row_inputs = []\n",
    "            for c in range(3):\n",
    "                spinbox = QDoubleSpinBox()\n",
    "                spinbox.setMinimum(-100.0)\n",
    "                spinbox.setMaximum(100.0)\n",
    "                spinbox.setValue(0.0)\n",
    "                # Set center to 1.0 for an identity-like default\n",
    "                if r == 1 and c == 1:\n",
    "                    spinbox.setValue(1.0)\n",
    "                grid_layout.addWidget(spinbox, r, c)\n",
    "                row_inputs.append(spinbox)\n",
    "            self.kernel_inputs.append(row_inputs)\n",
    "        layout.addLayout(grid_layout)\n",
    "\n",
    "    def get_params(self) -> dict:\n",
    "        kernel = np.array([[spinbox.value() for spinbox in row] for row in self.kernel_inputs])\n",
    "        return {'kernel': kernel}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c179a2a7-3007-4a95-8bd2-30e5bcc965e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "class CLAHEParamsWidget(BaseParamsWidget):\n",
    "    \"\"\"Widget for CLAHE parameters.\"\"\"\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "        layout = QVBoxLayout(self)\n",
    "        layout.setContentsMargins(0, 0, 0, 0)\n",
    "        \n",
    "        # Clip limit parameter\n",
    "        layout.addWidget(QLabel(\"Clip Limit:\"))\n",
    "        self.clip_spinbox = QDoubleSpinBox()\n",
    "        self.clip_spinbox.setMinimum(0.1)\n",
    "        self.clip_spinbox.setMaximum(10.0)\n",
    "        self.clip_spinbox.setValue(2.0)  # Default value\n",
    "        self.clip_spinbox.setSingleStep(0.1)\n",
    "        layout.addWidget(self.clip_spinbox)\n",
    "        \n",
    "        # Tile size parameter\n",
    "        layout.addWidget(QLabel(\"Tile Size (Grid):\"))\n",
    "        self.tile_spinbox = QDoubleSpinBox()\n",
    "        self.tile_spinbox.setMinimum(2)\n",
    "        self.tile_spinbox.setMaximum(32)\n",
    "        self.tile_spinbox.setValue(8)  # Default 8x8 tiles\n",
    "        self.tile_spinbox.setSingleStep(1)\n",
    "        layout.addWidget(self.tile_spinbox)\n",
    "        \n",
    "        layout.addStretch()\n",
    "    \n",
    "    def get_params(self) -> dict:\n",
    "        return {\n",
    "            'clip_limit': self.clip_spinbox.value(),\n",
    "            'tile_size': int(self.tile_spinbox.value())\n",
    "        }\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a121e53-d747-48d6-ace2-83ac74207aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "class DopplerBoostParamsWidget(BaseParamsWidget):\n",
    "    \"\"\"Widget for Relativistic Doppler Boosting parameters.\"\"\"\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "        layout = QVBoxLayout(self)\n",
    "        layout.setContentsMargins(0, 0, 0, 0)\n",
    "        \n",
    "        # Velocity parameter (fraction of speed of light)\n",
    "        layout.addWidget(QLabel(\"Velocity (fraction of c):\"))\n",
    "        self.velocity_spinbox = QDoubleSpinBox()\n",
    "        self.velocity_spinbox.setMinimum(0.1)\n",
    "        self.velocity_spinbox.setMaximum(0.9)  # Up to 90% speed of light\n",
    "        self.velocity_spinbox.setValue(0.5)  # Default 0.5c\n",
    "        self.velocity_spinbox.setSingleStep(0.05)\n",
    "        layout.addWidget(self.velocity_spinbox)\n",
    "        \n",
    "        # Viewing angle parameter\n",
    "        layout.addWidget(QLabel(\"Viewing Angle (degrees):\"))\n",
    "        self.angle_spinbox = QDoubleSpinBox()\n",
    "        self.angle_spinbox.setMinimum(0)\n",
    "        self.angle_spinbox.setMaximum(180)\n",
    "        self.angle_spinbox.setValue(90)  # Default edge-on view\n",
    "        self.angle_spinbox.setSingleStep(5)\n",
    "        layout.addWidget(self.angle_spinbox)\n",
    "        \n",
    "        layout.addStretch()\n",
    "    \n",
    "    def get_params(self) -> dict:\n",
    "        return {\n",
    "            'velocity': self.velocity_spinbox.value(),\n",
    "            'angle': self.angle_spinbox.value()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13884d0d-5474-4621-af72-f7d796b8c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Define a custom control widget\n",
    "class SampleControlsWidget(QWidget):\n",
    "    # Signal to request processing from the module manager\n",
    "    process_requested = Signal(dict)\n",
    "\n",
    "    def __init__(self, module_manager, parent=None):\n",
    "        super().__init__(parent)\n",
    "        self.module_manager = module_manager\n",
    "        self.param_widgets = {}\n",
    "        self.setup_ui()\n",
    "\n",
    "    def setup_ui(self):\n",
    "        layout = QVBoxLayout(self)\n",
    "        layout.addWidget(QLabel(\"<h3>Control Panel</h3>\"))\n",
    "\n",
    "        layout.addWidget(QLabel(\"Operation:\"))\n",
    "        self.operation_selector = QComboBox()\n",
    "        layout.addWidget(self.operation_selector)\n",
    "\n",
    "        # Stacked widget to hold the parameter UIs\n",
    "        self.params_stack = QStackedWidget()\n",
    "        layout.addWidget(self.params_stack)\n",
    "\n",
    "        # Define operations and their corresponding parameter widgets\n",
    "        operations = {\n",
    "            \"Gaussian Blur\": GaussianParamsWidget,\n",
    "            \"Sobel Edge Detect\": NoParamsWidget,\n",
    "            \"Power Law (Gamma)\": PowerLawParamsWidget,\n",
    "            \"Convolution\": ConvolutionParamsWidget,\n",
    "            \"CLAHE Enhancement\":CLAHEParamsWidget,\n",
    "            \"Relativistic Doppler Boosting\":DopplerBoostParamsWidget,\n",
    "            \"Canny Edge Detection\":NoParamsWidget\n",
    "        }\n",
    "\n",
    "        for name, widget_class in operations.items():\n",
    "            widget = widget_class()\n",
    "            self.params_stack.addWidget(widget)\n",
    "            self.param_widgets[name] = widget\n",
    "            self.operation_selector.addItem(name)\n",
    "\n",
    "        self.apply_button = QPushButton(\"Apply Processing\")\n",
    "        layout.addWidget(self.apply_button)\n",
    "\n",
    "        self.apply_button.clicked.connect(self._on_apply_clicked)\n",
    "        self.operation_selector.currentTextChanged.connect(self._on_operation_changed)\n",
    "\n",
    "    def _on_apply_clicked(self):\n",
    "        operation_name = self.operation_selector.currentText()\n",
    "        active_widget = self.param_widgets[operation_name]\n",
    "        params = active_widget.get_params()\n",
    "        params['operation'] = operation_name # Add operation name to params\n",
    "        self.process_requested.emit(params)\n",
    "\n",
    "    def _on_operation_changed(self, operation_name: str):\n",
    "        if operation_name in self.param_widgets:\n",
    "            self.params_stack.setCurrentWidget(self.param_widgets[operation_name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e0e78ee-4c74-4be4-9863-f165a4bb886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "class SampleImageModule(IImageModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._controls_widget = None\n",
    "\n",
    "    def get_name(self) -> str:\n",
    "        return \"Sample Module\"\n",
    "\n",
    "    def get_supported_formats(self) -> list[str]:\n",
    "        return [\"png\", \"jpg\", \"jpeg\", \"bmp\", \"gif\", \"tiff\"] # Common formats\n",
    "\n",
    "    def create_control_widget(self, parent=None, module_manager=None) -> QWidget:\n",
    "        if self._controls_widget is None:\n",
    "            self._controls_widget = SampleControlsWidget(module_manager, parent)\n",
    "            # The widget's signal is connected to the module's handler\n",
    "            self._controls_widget.process_requested.connect(self._handle_processing_request)\n",
    "        return self._controls_widget\n",
    "\n",
    "    def _handle_processing_request(self, params: dict):\n",
    "        # Here, the module needs a way to trigger processing in the main app\n",
    "        # The control widget now has a valid reference to the module manager\n",
    "        if self._controls_widget and self._controls_widget.module_manager:\n",
    "            self._controls_widget.module_manager.apply_processing_to_current_image(params)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d43248-b4f8-470b-8664-1d2765993e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "def load_image(self, file_path: str):\n",
    "        try:\n",
    "            image_data = imageio.imread(file_path)\n",
    "            # Ensure 2D images are correctly shaped (e.g., handle grayscale vs RGB)\n",
    "            if image_data.ndim == 3 and image_data.shape[2] in [3, 4]: # RGB or RGBA\n",
    "                # napari handles this well, but for processing, sometimes a single channel is needed\n",
    "                pass\n",
    "            elif image_data.ndim == 2: # Grayscale\n",
    "                image_data = image_data[np.newaxis, :] # Add a channel dimension for consistency if desired\n",
    "            else:\n",
    "                print(f\"Warning: Unexpected image dimensions {image_data.shape}\")\n",
    "\n",
    "            metadata = {'name': file_path.split('/')[-1]}\n",
    "            # Add more metadata: original_shape, file_size, etc.\n",
    "            return True, image_data, metadata, None # Session ID generated by store\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading 2D image {file_path}: {e}\")\n",
    "            return False, None, {}, None\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aaa31fc-2f60-4c14-8a77-de1d3a1176cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "def process_image(self, image_data: np.ndarray, metadata: dict, params: dict) -> np.ndarray:\n",
    "        processed_data = image_data.copy()\n",
    "\n",
    "        operation = params.get('operation')\n",
    "\n",
    "        if operation == \"Gaussian Blur\":\n",
    "            sigma = params.get('sigma', 1.0)\n",
    "            # skimage.filters.gaussian expects float data\n",
    "            processed_data = skimage.filters.gaussian(processed_data.astype(float), sigma=sigma, preserve_range=True)\n",
    "        elif operation == \"Median Filter\":\n",
    "            filter_size = params.get('filter_size', 3)\n",
    "            if filter_size <= 1: return processed_data # No change\n",
    "            # skimage.filters.median\n",
    "            if processed_data.ndim == 3 and processed_data.shape[2] in [3, 4]: # RGB/RGBA\n",
    "                # Apply to each channel\n",
    "                channels = []\n",
    "                for i in range(processed_data.shape[2]):\n",
    "                    channels.append(skimage.filters.median(processed_data[:,:,i], footprint=skimage.morphology.disk(int(filter_size/2))))\n",
    "                processed_data = np.stack(channels, axis=-1)\n",
    "            else:\n",
    "                processed_data = skimage.filters.median(processed_data, footprint=skimage.morphology.disk(int(filter_size/2)))\n",
    "        elif operation == \"Sobel Edge Detect\":\n",
    "            # Sobel works on 2D (grayscale) images. Convert if necessary.\n",
    "            if processed_data.ndim == 3 and processed_data.shape[2] in [3, 4]:\n",
    "                grayscale_img = rgb2gray(processed_data[:,:,:3])\n",
    "            else:\n",
    "                grayscale_img = processed_data\n",
    "            \n",
    "            processed_data = skimage.filters.sobel(grayscale_img)\n",
    "        elif operation == \"Power Law (Gamma)\":\n",
    "            gamma = params.get('gamma', 1.0)\n",
    "            # Normalize to [0, 1]\n",
    "            input_float = processed_data.astype(float)\n",
    "            max_val = np.max(input_float)\n",
    "            if max_val > 0:\n",
    "                normalized = input_float / max_val\n",
    "                # Apply gamma correction\n",
    "                gamma_corrected = np.power(normalized, gamma)\n",
    "                # Scale back to original range\n",
    "                processed_data = gamma_corrected * max_val\n",
    "        \n",
    "        elif operation == \"Convolution\":\n",
    "            kernel = params.get('kernel')\n",
    "            if kernel is not None:\n",
    "                # Convolve works best on float images\n",
    "                input_float = processed_data.astype(float)\n",
    "                if input_float.ndim == 3 and input_float.shape[2] in [3, 4]: # RGB/RGBA\n",
    "                    channels = []\n",
    "                    for i in range(input_float.shape[2]):\n",
    "                        channels.append(convolve(input_float[:,:,i], kernel, mode='reflect'))\n",
    "                    processed_data = np.stack(channels, axis=-1)\n",
    "                else:\n",
    "                    processed_data = convolve(input_float, kernel, mode='reflect')\n",
    "        elif operation == \"CLAHE Enhancement\":\n",
    "            clip_limit = params.get('clip_limit', 2.0)\n",
    "            tile_size = params.get('tile_size', 8)\n",
    "            \n",
    "            # Convert to grayscale if color image\n",
    "            if processed_data.ndim == 3 and processed_data.shape[2] in [3, 4]:\n",
    "                grayscale_img = rgb2gray(processed_data[:,:,:3])\n",
    "                was_color = True\n",
    "            else:\n",
    "                grayscale_img = processed_data.copy()\n",
    "                was_color = False\n",
    "            \n",
    "            # Normalize to [0, 255] range\n",
    "            img_min = grayscale_img.min()\n",
    "            img_max = grayscale_img.max()\n",
    "            if img_max > img_min:\n",
    "                normalized = ((grayscale_img - img_min) / (img_max - img_min) * 255).astype(np.uint8)\n",
    "            else:\n",
    "                normalized = grayscale_img.astype(np.uint8)\n",
    "            \n",
    "            # Calculate tile dimensions\n",
    "            height, width = normalized.shape\n",
    "            tile_h = height // tile_size\n",
    "            tile_w = width // tile_size\n",
    "            \n",
    "            # Create output array\n",
    "            clahe_img = np.zeros_like(normalized, dtype=np.float32)\n",
    "            \n",
    "            # Process each tile\n",
    "            for i in range(tile_size):\n",
    "                for j in range(tile_size):\n",
    "                    # Calculate tile boundaries\n",
    "                    y1 = i * tile_h\n",
    "                    y2 = (i + 1) * tile_h if i < tile_size - 1 else height\n",
    "                    x1 = j * tile_w\n",
    "                    x2 = (j + 1) * tile_w if j < tile_size - 1 else width\n",
    "                    \n",
    "                    tile = normalized[y1:y2, x1:x2]\n",
    "                    \n",
    "                    # Compute histogram\n",
    "                    hist, bins = np.histogram(tile.flatten(), bins=256, range=(0, 256))\n",
    "                    \n",
    "                    # Clip histogram\n",
    "                    clip_threshold = clip_limit * (tile.size / 256.0)\n",
    "                    clipped_hist = np.minimum(hist, clip_threshold)\n",
    "                    \n",
    "                    # Redistribute clipped pixels\n",
    "                    excess = np.sum(hist - clipped_hist)\n",
    "                    redistribute = excess / 256.0\n",
    "                    clipped_hist = clipped_hist + redistribute\n",
    "                    \n",
    "                    # Compute CDF\n",
    "                    cdf = np.cumsum(clipped_hist)\n",
    "                    cdf = cdf / cdf[-1]  # Normalize to [0, 1]\n",
    "                    \n",
    "                    # Map intensities using CDF\n",
    "                    equalized_tile = np.interp(tile.flatten(), bins[:-1], cdf * 255)\n",
    "                    equalized_tile = equalized_tile.reshape(tile.shape)\n",
    "                    \n",
    "                    # Store result\n",
    "                    clahe_img[y1:y2, x1:x2] = equalized_tile\n",
    "            \n",
    "            # Convert back to original range\n",
    "            if img_max > img_min:\n",
    "                clahe_img = (clahe_img / 255.0) * (img_max - img_min) + img_min\n",
    "            \n",
    "            # Store result\n",
    "            processed_data = clahe_img.astype(image_data.dtype)\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "        elif operation == \"Relativistic Doppler Boosting\":\n",
    "            velocity = params.get('velocity', 0.5)  # fraction of c\n",
    "            viewing_angle = params.get('angle', 90)  # degrees\n",
    "            \n",
    "            # Convert to grayscale if needed\n",
    "            if processed_data.ndim == 3 and processed_data.shape[2] in [3, 4]:\n",
    "                grayscale_img = rgb2gray(processed_data[:,:,:3])\n",
    "            else:\n",
    "                grayscale_img = processed_data.copy()\n",
    "            \n",
    "            # Find image center (black hole location)\n",
    "            height, width = grayscale_img.shape\n",
    "            center_y = height // 2\n",
    "            center_x = width // 2\n",
    "            \n",
    "            # Create coordinate grids\n",
    "            y, x = np.ogrid[0:height, 0:width]\n",
    "            dy = y - center_y\n",
    "            dx = x - center_x\n",
    "            \n",
    "            # Calculate distance from center\n",
    "            r = np.sqrt(dx**2 + dy**2)\n",
    "            \n",
    "            # Calculate angle around ring (φ)\n",
    "            # phi = 0 at right, π/2 at top, π at left, -π/2 at bottom\n",
    "            phi = np.arctan2(dy, dx)\n",
    "            \n",
    "            # Calculate Lorentz factor\n",
    "            gamma = 1.0 / np.sqrt(1.0 - velocity**2)\n",
    "            \n",
    "            # Convert viewing angle to radians\n",
    "            theta = np.radians(viewing_angle)\n",
    "            \n",
    "            # Calculate velocity component toward observer\n",
    "            # For edge-on view (θ=90°): v_radial = v × cos(φ)\n",
    "            # cos(φ) = +1 at right (perpendicular), 0 at bottom (approaching), -1 at left\n",
    "            beta_radial = velocity * np.sin(theta) * np.cos(phi)\n",
    "            \n",
    "            # Calculate Doppler factor: δ = 1 / [γ(1 - β·cos(φ))]\n",
    "            doppler_factor = 1.0 / (gamma * (1.0 - beta_radial))\n",
    "            \n",
    "            # Clip to reasonable range (avoid extreme values)\n",
    "            doppler_factor = np.clip(doppler_factor, 0.1, 10.0)\n",
    "            \n",
    "            # Apply relativistic beaming: I' = I × δ³\n",
    "            boosted = grayscale_img.astype(float) * (doppler_factor ** 3)\n",
    "            \n",
    "            # Create ring mask (apply only to ring, not center shadow)\n",
    "            inner_radius = height * 0.15  # Shadow boundary\n",
    "            outer_radius = height * 0.48  # Outer ring edge\n",
    "            ring_mask = (r > inner_radius) & (r < outer_radius)\n",
    "            \n",
    "            # Apply boosting only to ring region\n",
    "            result = grayscale_img.astype(float).copy()\n",
    "            result[ring_mask] = boosted[ring_mask]\n",
    "            \n",
    "            # Normalize to avoid overflow\n",
    "            result = np.clip(result, 0, 255)\n",
    "            \n",
    "            # Convert back to original type\n",
    "            processed_data = result.astype(image_data.dtype)\n",
    "\n",
    "        elif operation == \"Canny Edge Detection\":\n",
    "            # Convert to grayscale\n",
    "            if processed_data.ndim == 3 and processed_data.shape[2] in [3, 4]:\n",
    "                grayscale_img = rgb2gray(processed_data[:,:,:3])\n",
    "            else:\n",
    "                grayscale_img = processed_data.copy()\n",
    "            \n",
    "            # Step 1: Gaussian smoothing\n",
    "            smoothed = skimage.filters.gaussian(grayscale_img, sigma=1.0)\n",
    "            \n",
    "            # Step 2: Calculate gradients using Sobel operators\n",
    "            sobel_x = np.array([[-1, 0, 1],\n",
    "                                [-2, 0, 2],\n",
    "                                [-1, 0, 1]], dtype=float)\n",
    "            sobel_y = np.array([[-1, -2, -1],\n",
    "                                [ 0,  0,  0],\n",
    "                                [ 1,  2,  1]], dtype=float)\n",
    "            \n",
    "            Gx = convolve(smoothed, sobel_x)\n",
    "            Gy = convolve(smoothed, sobel_y)\n",
    "            \n",
    "            # Step 3: Calculate magnitude and direction\n",
    "            G = np.sqrt(Gx**2 + Gy**2)\n",
    "            theta = np.arctan2(Gy, Gx)\n",
    "            \n",
    "            # Step 4: Non-maximum suppression\n",
    "            height, width = G.shape\n",
    "            nms = np.zeros_like(G)\n",
    "            \n",
    "            # Convert angle to degrees and round to nearest 45°\n",
    "            angle_deg = np.degrees(theta) % 180\n",
    "            \n",
    "            for i in range(1, height - 1):\n",
    "                for j in range(1, width - 1):\n",
    "                    # Determine direction\n",
    "                    angle = angle_deg[i, j]\n",
    "                    \n",
    "                    # 0° or 180° - horizontal edge (compare top and bottom)\n",
    "                    if (0 <= angle < 22.5) or (157.5 <= angle <= 180):\n",
    "                        neighbors = [G[i, j-1], G[i, j+1]]\n",
    "                    # 45° - diagonal edge (compare NE and SW)\n",
    "                    elif 22.5 <= angle < 67.5:\n",
    "                        neighbors = [G[i-1, j+1], G[i+1, j-1]]\n",
    "                    # 90° - vertical edge (compare left and right)\n",
    "                    elif 67.5 <= angle < 112.5:\n",
    "                        neighbors = [G[i-1, j], G[i+1, j]]\n",
    "                    # 135° - diagonal edge (compare NW and SE)\n",
    "                    else:\n",
    "                        neighbors = [G[i-1, j-1], G[i+1, j+1]]\n",
    "                    \n",
    "                    # Keep pixel only if it's maximum along gradient direction\n",
    "                    if G[i, j] >= max(neighbors):\n",
    "                        nms[i, j] = G[i, j]\n",
    "            \n",
    "            # Step 5: Double thresholding\n",
    "            T_high = 0.3 * np.max(nms)\n",
    "            T_low = 0.1 * np.max(nms)\n",
    "            \n",
    "            strong_edges = nms > T_high\n",
    "            weak_edges = (nms >= T_low) & (nms <= T_high)\n",
    "            \n",
    "            # Step 6: Edge tracking by hysteresis\n",
    "            from scipy.ndimage import binary_dilation\n",
    "            \n",
    "            edges = strong_edges.copy()\n",
    "            \n",
    "            # Iteratively grow strong edges into weak edges\n",
    "            for _ in range(10):\n",
    "                dilated = binary_dilation(edges)\n",
    "                new_edges = dilated & weak_edges\n",
    "                if not np.any(new_edges & ~edges):\n",
    "                    break  # No new edges found\n",
    "                edges = edges | new_edges\n",
    "            \n",
    "            # Convert to 8-bit image\n",
    "            processed_data = (edges * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "        # Ensure output data type is consistent (e.g., convert back to uint8 if processing changed it)\n",
    "        processed_data = processed_data.astype(image_data.dtype)\n",
    "\n",
    "        return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb73c5-fb4b-4a5b-a31a-e94887e16507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.11 (SRH Project)",
   "language": "python",
   "name": "srh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
